{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaaxS0p8CqVC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import Required Modules\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import keras\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers import *\n",
        "import keras.backend as k\n",
        "from keras.models import *\n",
        "from keras.optimizers import *\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread, imshow, imsave, imread_collection\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping"
      ],
      "metadata": {
        "id": "YSMBajFyC6R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define Train & Test Path (Images + Mask Path for Train and Test Stages)\n",
        "\n",
        "TRAIN_IMAGE_PATH = 'gdrive/My Drive/Berea_Sand_Texas/Image_Berea_UF_512_'\n",
        "TRAIN_MASK_PATH = 'gdrive/My Drive/Berea_Sand_Texas/Mask_Berea_512_'"
      ],
      "metadata": {
        "id": "9vRXtdhsDC78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Initialize Images and Mask Size\n",
        "\n",
        "IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS = 64, 64, 64, 1\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS)"
      ],
      "metadata": {
        "id": "4469WeCKDHS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import cv2\n",
        "\n",
        "Train_Input = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Parker_Sand/Image_512x512/*.png\"))]\n",
        "Train_Mask = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Parker_Sand/Label_512x512/*.png\"))]\n",
        "\n",
        "Train_Input = np.array(Train_Input)\n",
        "Train_Mask = np.array(Train_Mask)\n",
        "\n",
        "Train_Mask = cv2.normalize(Train_Mask, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ],
      "metadata": {
        "id": "zzfdrlT0DJlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import cv2\n",
        "\n",
        "Train_Input_1 = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Berea_Sand/Image_Berea_UF_512/*.png\"))]\n",
        "Train_Mask_1 = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Berea_Sand/Mask_berea_512/*.png\"))]\n",
        "\n",
        "Train_Input_1 = np.array(Train_Input)\n",
        "Train_Mask_1 = np.array(Train_Mask)\n",
        "\n",
        "Train_Mask_1 = cv2.normalize(Train_Mask_1, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ],
      "metadata": {
        "id": "_opL711MgIdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import cv2\n",
        "\n",
        "Train_Input_2 = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Bandera_Gray_Sand/Image_512x512/*.png\"))]\n",
        "Train_Mask_2 = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Bandera_Gray_Sand/Label_512x512/*.png\"))]\n",
        "\n",
        "Train_Input_2 = np.array(Train_Input_2)\n",
        "Train_Mask_2 = np.array(Train_Mask_2)\n",
        "\n",
        "Train_Mask_2 = cv2.normalize(Train_Mask_2, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ],
      "metadata": {
        "id": "a7mg7lce1-ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_Input_3D = np.stack(Train_Input, axis=2)\n",
        "Train_Mask_3D = np.stack(Train_Mask, axis=2)\n",
        "\n",
        "Train_Input_3D_1 = np.stack(Train_Input_1, axis=2)\n",
        "Train_Mask_3D_1 = np.stack(Train_Mask_1, axis=2)\n",
        "\n",
        "#Train_Input_3D_2 = np.stack(Train_Input_2, axis=2)\n",
        "#Train_Mask_3D_2 = np.stack(Train_Mask_2, axis=2)"
      ],
      "metadata": {
        "id": "Mh8l16GkUDF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Train_Input_3D.shape)\n",
        "print(Train_Input_3D_1.shape)\n",
        "#print(Train_Input_3D_2.shape)"
      ],
      "metadata": {
        "id": "0C7phc4CDLpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patchify"
      ],
      "metadata": {
        "id": "hFIwHH4SDW8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from patchify import *"
      ],
      "metadata": {
        "id": "5vAJbS-DDY7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_Input_3D_Patches = patchify(Train_Input_3D,(64,64,64), step=64)\n",
        "Train_Mask_3D_Patches = patchify(Train_Mask_3D,(64,64,64), step=64)\n",
        "\n",
        "Train_Input_3D_Patches_1 = patchify(Train_Input_3D_1,(64,64,64), step=64)\n",
        "Train_Mask_3D_Patches_1 = patchify(Train_Mask_3D_1,(64,64,64), step=64)\n",
        "\n",
        "#Train_Input_3D_Patches_2 = patchify(Train_Input_3D_2,(64,64,64), step=64)\n",
        "#Train_Mask_3D_Patches_2 = patchify(Train_Mask_3D_2,(64,64,64), step=64)"
      ],
      "metadata": {
        "id": "FpholAY_DbDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Train_Mask_3D_Patches.shape)\n",
        "print(Train_Mask_3D_Patches_1.shape)\n",
        "#print(Train_Mask_3D_Patches_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R_uXy9IDfKv",
        "outputId": "84a92069-e08b-4da0-9a61-775a0744d307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 8, 15, 64, 64, 64)\n",
            "(8, 8, 15, 64, 64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train_Input_3D_Patche = np.reshape(Train_Input_3D_Patches, (-1, Train_Input_3D_Patches.shape[3], Train_Input_3D_Patches.shape[4], Train_Input_3D_Patches.shape[5]))\n",
        "Train_Mask_3D_Patche = np.reshape(Train_Mask_3D_Patches, (-1, Train_Input_3D_Patches.shape[3], Train_Input_3D_Patches.shape[4], Train_Input_3D_Patches.shape[5]))\n",
        "\n",
        "Train_Input_3D_Patche_1 = np.reshape(Train_Input_3D_Patches_1, (-1, Train_Input_3D_Patches_1.shape[3], Train_Input_3D_Patches_1.shape[4], Train_Input_3D_Patches_1.shape[5]))\n",
        "Train_Mask_3D_Patche_1 = np.reshape(Train_Mask_3D_Patches_1, (-1, Train_Input_3D_Patches_1.shape[3], Train_Input_3D_Patches_1.shape[4], Train_Input_3D_Patches_1.shape[5]))\n",
        "\n",
        "#Train_Input_3D_Patche_2 = np.reshape(Train_Input_3D_Patches_2, (-1, Train_Input_3D_Patches_2.shape[3], Train_Input_3D_Patches_2.shape[4], Train_Input_3D_Patches_2.shape[5]))\n",
        "#Train_Mask_3D_Patche_2 = np.reshape(Train_Mask_3D_Patches_2, (-1, Train_Input_3D_Patches_2.shape[3], Train_Input_3D_Patches_2.shape[4], Train_Input_3D_Patches_2.shape[5]))"
      ],
      "metadata": {
        "id": "ByP9cRzeDhWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Train_Mask_3D_Patche.shape)\n",
        "print(Train_Mask_3D_Patche_1.shape)\n",
        "#print(Train_Mask_3D_Patche_2.shape)"
      ],
      "metadata": {
        "id": "N0wl79qjDjGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_Input_3D_Patche = (Train_Input_3D_Patche, Train_Input_3D_Patche_1)  #, Train_Input_3D_Patche_2\n",
        "Train_Mask_3D_Patche = (Train_Mask_3D_Patche, Train_Mask_3D_Patche_1)  #, Train_Mask_3D_Patche_2\n",
        "\n",
        "Train_Input_3D_Patche = np.array(Train_Input_3D_Patche)\n",
        "Train_Mask_3D_Patche = np.array(Train_Mask_3D_Patche)\n",
        "\n",
        "Train_Input_3D_Patche = np.reshape(Train_Input_3D_Patche, (-1, Train_Input_3D_Patche.shape[2], Train_Input_3D_Patche.shape[3], Train_Input_3D_Patche.shape[4]))\n",
        "Train_Mask_3D_Patche = np.reshape(Train_Mask_3D_Patche, (-1, Train_Mask_3D_Patche.shape[2], Train_Mask_3D_Patche.shape[3], Train_Mask_3D_Patche.shape[4]))"
      ],
      "metadata": {
        "id": "ot1xa1jmUzQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Train_Input_3D_Patche.shape)\n",
        "print(Train_Mask_3D_Patche.shape)"
      ],
      "metadata": {
        "id": "vN0zmISdU2mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.math.sigmoid(y_pred)\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "\n",
        "    return 1 - numerator / denominator\n",
        "\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = k.flatten(y_true)\n",
        "    y_pred_f = k.flatten(y_pred)\n",
        "    intersection = k.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (k.sum(y_true_f) + k.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = k.sum(k.abs(y_true * y_pred), axis=[1,2])\n",
        "  union = k.sum(y_true,[1,2])+k.sum(y_pred,[1,2])-intersection\n",
        "  iou = k.mean((intersection+smooth) / (union+smooth), axis=0)\n",
        "  return iou\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = k.sum(k.round(k.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = k.sum(k.round(k.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + k.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = k.sum(k.round(k.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = k.sum(k.round(k.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + k.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "   precision = precision_m(y_true, y_pred)\n",
        "   recall = recall_m(y_true, y_pred)\n",
        "   return 2*((precision*recall)/(precision+recall+k.epsilon()))"
      ],
      "metadata": {
        "id": "Bksq_X7olNNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Att_Res_U_Net_3D_Segmentation(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS)):\n",
        "\n",
        "    inputs = Input(input_size)\n",
        "    n = Lambda(lambda x:x/255)(inputs)\n",
        "\n",
        "\n",
        "    c1 = Conv3D(16, (3,3,3), activation='relu', padding='same', kernel_initializer=tf.keras.initializers.Ones())(n)\n",
        "    #c1 = BatchNormalization(axis=3)(c1)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv3D(16, (3,3,3), padding='same')(c1)\n",
        "    #c1 = BatchNormalization(axis=3)(c1)\n",
        "    shortcut1 = Conv3D(16, (1,1,1), padding='same')(n)\n",
        "    #shortcut1 = BatchNormalization(axis=3)(shortcut1)\n",
        "\n",
        "    Res_Path1 = add([shortcut1,c1])\n",
        "    out1 = Activation('relu')(Res_Path1)\n",
        "\n",
        "    p1 = MaxPooling3D((2,2,2))(out1)\n",
        "\n",
        "    c2 = Conv3D(32, (3,3,3), activation='relu', padding='same')(p1)\n",
        "    #c2 = BatchNormalization(axis=3)(c2)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv3D(32, (3,3,3), padding='same')(c2)\n",
        "    #c2 = BatchNormalization(axis=3)(c2)\n",
        "    shortcut2 = Conv3D(32, (1,1,1), padding='same')(p1)\n",
        "    #shortcut2 = BatchNormalization(axis=3)(shortcut2)\n",
        "\n",
        "    Res_Path2 = add([shortcut2,c2])\n",
        "    out2 = Activation('relu')(Res_Path2)\n",
        "\n",
        "    p2 = MaxPooling3D((2,2,2))(out2)\n",
        "\n",
        "\n",
        "    c3 = Conv3D(64, (3,3,3), activation='relu', padding='same')(p2)\n",
        "    #c3 =  BatchNormalization(axis=3)(c3)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv3D(64, (3,3,3), padding='same')(c3)\n",
        "    #c3 =  BatchNormalization(axis=3)(c3)\n",
        "    shortcut3 = Conv3D(64, (1,1,1), padding='same')(p2)\n",
        "    #shortcut3 =  BatchNormalization(axis=3)(shortcut3)\n",
        "\n",
        "    Res_Path3 = add([shortcut3,c3])\n",
        "    out3 = Activation('relu')(Res_Path3)\n",
        "\n",
        "    p3 = MaxPooling3D((2,2,2))(out3)\n",
        "\n",
        "\n",
        "    c4 = Conv3D(128, (3,3,3), activation='relu', padding='same')(p3)\n",
        "    #c4 =  BatchNormalization(axis=3)(c4)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv3D(128, (3,3,3), padding='same')(c4)\n",
        "    #c4 =  BatchNormalization(axis=3)(c4)\n",
        "    shortcut4 = Conv3D(128, (1,1,1), padding='same')(p3)\n",
        "    #shortcut4 =  BatchNormalization(axis=3)(shortcut4)\n",
        "\n",
        "    Res_Path4 = add([shortcut4,c4])\n",
        "    out4 = Activation('relu')(Res_Path4)\n",
        "\n",
        "    p4 = MaxPooling3D((2,2,2))(out4)\n",
        "\n",
        "\n",
        "    c5 = Conv3D(256, (3,3,3), activation='elu', padding='same')(p4)\n",
        "    #c5 =  BatchNormalization(axis=3)(c5)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv3D(256, (3,3,3), padding='same')(c5)\n",
        "    #c5 = BatchNormalization(axis=3)(c5)\n",
        "    shortcut5 = Conv3D(256, (1,1,1), padding='same')(p4)\n",
        "    #shortcut5 =  BatchNormalization(axis=3)(shortcut5)\n",
        "\n",
        "    Res_Path5 = add([shortcut5,c5])\n",
        "    out5 = Activation('relu')(Res_Path5)\n",
        "\n",
        "\n",
        "    u6 = Conv3DTranspose(128, (2,2,2), strides=(2,2,2), padding='same')(out5)\n",
        "\n",
        "\n",
        "    theta_x_1 = Conv3D(64, (1,1,1), strides=(2,2,2), padding='same')(out4)\n",
        "    #theta_x_1 = BatchNormalization(axis=3)(theta_x_1)\n",
        "    shape_x_1 = k.int_shape(out4)\n",
        "    phi_g_1 = Conv3D(64, (1,1,1), strides=(1,1,1), padding='same')(out5)\n",
        "    #phi_g_1 = BatchNormalization(axis=3)(phi_g_1)\n",
        "    conc_xg_1 = add([phi_g_1, theta_x_1])\n",
        "    act_xg_1 = Activation('relu')(conc_xg_1)\n",
        "    psi_1 = Conv3D(1, (1,1,1), strides=(1,1,1), padding='same')(act_xg_1)\n",
        "    #psi_1 = BatchNormalization(axis=3)(psi_1)\n",
        "    sigm_xg_1 = Activation('sigmoid')(psi_1)\n",
        "    shape_sigm_1 = k.int_shape(sigm_xg_1)\n",
        "    upsample_xg_1 = UpSampling3D(size=(shape_x_1[1]//shape_sigm_1[1], shape_x_1[2]//shape_sigm_1[2], shape_x_1[3]//shape_sigm_1[3]))(sigm_xg_1)\n",
        "    y1 = multiply([upsample_xg_1, out4])\n",
        "\n",
        "\n",
        "    conc6 = concatenate([u6, y1])\n",
        "\n",
        "    c6 = Conv3D(128, (3,3,3), activation='relu', padding='same')(conc6)\n",
        "    #c6 = BatchNormalization(axis=3)(c6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv3D(128, (3,3,3), padding='same')(c6)\n",
        "    #c6 = BatchNormalization(axis=3)(c6)\n",
        "    shortcut6 = Conv3D(128, (1,1,1), padding='same')(u6)\n",
        "    #shortcut6 = BatchNormalization(axis=3)(shortcut6)\n",
        "\n",
        "    Res_Path6 = add([shortcut6,c6])\n",
        "    out6 = Activation('relu')(Res_Path6)\n",
        "\n",
        "\n",
        "    u7 = Conv3DTranspose(64, (2,2,2), strides=(2,2,2), padding='same')(out6)\n",
        "\n",
        "\n",
        "    theta_x_2 = Conv3D(128, (1,1,1), strides=(2,2,2), padding='same')(out3)\n",
        "    #theta_x_2 = BatchNormalization(axis=3)(theta_x_2)\n",
        "    shape_x_2 = k.int_shape(out3)\n",
        "    phi_g_2 = Conv3D(128, (1,1,1), strides=(1,1,1), padding='same')(out6)\n",
        "    #phi_g_2 = BatchNormalization(axis=3)(phi_g_2)\n",
        "    conc_xg_2 = add([phi_g_2, theta_x_2])\n",
        "    act_xg_2 = Activation('relu')(conc_xg_2)\n",
        "    psi_2 = Conv3D(1, (1,1,1), strides=(1,1,1), padding='same')(act_xg_2)\n",
        "    #psi_2 = BatchNormalization(axis=3)(psi_2)\n",
        "    sigm_xg_2 = Activation('sigmoid')(psi_2)\n",
        "    shape_sigm_2 = k.int_shape(sigm_xg_2)\n",
        "    upsample_xg_2 = UpSampling3D(size=(shape_x_2[1]//shape_sigm_2[1], shape_x_2[2]//shape_sigm_2[2], shape_x_2[3]//shape_sigm_2[3]))(sigm_xg_2)\n",
        "    y2 = multiply([upsample_xg_2, out3])\n",
        "\n",
        "\n",
        "    conc7 = concatenate([u7, y2])\n",
        "\n",
        "    c7 = Conv3D(64, (3,3,3), activation='relu', padding='same')(conc7)\n",
        "    #c7 = BatchNormalization(axis=3)(c7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv3D(64, (3,3,3), padding='same')(c7)\n",
        "    #c7 = BatchNormalization(axis=3)(c7)\n",
        "    shortcut7 = Conv3D(64, (1,1,1), padding='same')(u7)\n",
        "    #shortcut7 = BatchNormalization(axis=3)(shortcut7)\n",
        "\n",
        "    Res_Path7 = add([shortcut7,c7])\n",
        "    out7 = Activation('relu')(Res_Path7)\n",
        "\n",
        "\n",
        "    u8 = Conv3DTranspose(32, (2,2,2), strides=(2,2,2), padding='same')(out7)\n",
        "\n",
        "\n",
        "    theta_x_3 = Conv3D(256, (1,1,1), strides=(2,2,2), padding='same')(out2)\n",
        "    #theta_x_3 = BatchNormalization(axis=3)(theta_x_3)\n",
        "    shape_x_3 = k.int_shape(out2)\n",
        "    phi_g_3 = Conv3D(256, (1,1,1), strides=(1,1,1), padding='same')(out7)\n",
        "    #phi_g_3 = BatchNormalization(axis=3)(phi_g_3)\n",
        "    conc_xg_3 = add([phi_g_3, theta_x_3])\n",
        "    act_xg_3 = Activation('relu')(conc_xg_3)\n",
        "    psi_3 = Conv3D(1, (1,1,1), strides=(1,1,1), padding='same')(act_xg_3)\n",
        "    #psi_3 = BatchNormalization(axis=3)(psi_3)\n",
        "    sigm_xg_3 = Activation('sigmoid')(psi_3)\n",
        "    shape_sigm_3 = k.int_shape(sigm_xg_3)\n",
        "    upsample_xg_3 = UpSampling3D(size=(shape_x_3[1]//shape_sigm_3[1], shape_x_3[2]//shape_sigm_3[2], shape_x_3[3]//shape_sigm_3[3]))(sigm_xg_3)\n",
        "    y3 = multiply([upsample_xg_3, out2])\n",
        "\n",
        "\n",
        "    conc8 = concatenate([u8, y3])\n",
        "\n",
        "    c8 = Conv3D(32, (3,3,3), activation='relu', padding='same')(conc8)\n",
        "    #c8 = BatchNormalization(axis=3)(c8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv3D(32, (3,3,3), padding='same')(c8)\n",
        "    #c8 = BatchNormalization(axis=3)(c8)\n",
        "    shortcut8 = Conv3D(32, (1,1,1), padding='same')(u8)\n",
        "    #shortcut8 = BatchNormalization(axis=3)(shortcut8)\n",
        "\n",
        "    Res_Path8 = add([shortcut8,c8])\n",
        "    out8 = Activation('relu')(Res_Path8)\n",
        "\n",
        "\n",
        "    u9 = Conv3DTranspose(16, (2,2,2), strides=(2,2,2), padding='same')(out8)\n",
        "\n",
        "\n",
        "    theta_x_4 = Conv3D(512, (1,1,1), strides=(2,2,2), padding='same')(out1)\n",
        "    #theta_x_4 = BatchNormalization(axis=3)(theta_x_4)\n",
        "    shape_x_4 = k.int_shape(out1)\n",
        "    phi_g_4 = Conv3D(512, (1,1,1), strides=(1,1,1), padding='same')(out8)\n",
        "    #phi_g_4 = BatchNormalization(axis=3)(phi_g_4)\n",
        "    conc_xg_4 = add([phi_g_4, theta_x_4])\n",
        "    act_xg_4 = Activation('relu')(conc_xg_4)\n",
        "    psi_4 = Conv3D(1, (1,1,1), strides=(1,1,1), padding='same')(act_xg_4)\n",
        "    #psi_4 = BatchNormalization(axis=3)(psi_4)\n",
        "    sigm_xg_4 = Activation('sigmoid')(psi_4)\n",
        "    shape_sigm_4 = k.int_shape(sigm_xg_4)\n",
        "    upsample_xg_4 = UpSampling3D(size=(shape_x_4[1]//shape_sigm_4[1], shape_x_4[2]//shape_sigm_4[2], shape_x_4[3]//shape_sigm_4[3]))(sigm_xg_4)\n",
        "    y4 = multiply([upsample_xg_4, out1])\n",
        "\n",
        "\n",
        "    conc9 = concatenate([u9, y4], axis = 4)\n",
        "\n",
        "    c9 = Conv3D(16, (3,3,3), activation='relu', padding='same')(conc9)\n",
        "    #c9 = BatchNormalization(axis=3)(c9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv3D(16, (3,3,3), padding='same')(c9)\n",
        "    #c9 = BatchNormalization(axis=3)(c9)\n",
        "    shortcut9 = Conv3D(16, (1,1,1), padding='same')(u9)\n",
        "    #shortcut9 = BatchNormalization(axis=3)(shortcut9)\n",
        "\n",
        "    Res_Path9 = add([shortcut9,c9])\n",
        "    out9 = Activation('relu')(Res_Path9)\n",
        "\n",
        "\n",
        "    outputs = Conv3D(1,(1,1,1), activation='sigmoid')(out9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss = ['binary_crossentropy'], metrics=[tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0, 1]), tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0]), tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1]), f1_m ,precision_m , recall_m, 'accuracy', jacard_coef])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "NevPwLypDsiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Att_Res_U_Net_3D_Segmentation()"
      ],
      "metadata": {
        "id": "9jV_rNMGDwqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model_Path = 'gdrive/My Drive/Saved_Models/3D_Att_Res_U_Net/Parker_Berea_IOU_F1_JC_ACC_3D_Att_Res_U_Net_Ones_0005'"
      ],
      "metadata": {
        "id": "n5deKAaRD4tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystopper = EarlyStopping(patience=20, verbose=1)\n",
        "checkpointer = ModelCheckpoint(Model_Path, verbose = 1, save_best_only=True)"
      ],
      "metadata": {
        "id": "2XANCZnnUyB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Validation_Input_3D_Patche = Train_Input_3D_Patche[:384]\n",
        "Train_Input_3D_Patche = Train_Input_3D_Patche[384:]\n",
        "Validation_Mask_3D_Patche = Train_Mask_3D_Patche[:384]\n",
        "Train_Mask_3D_Patche = Train_Mask_3D_Patche[384:]"
      ],
      "metadata": {
        "id": "PIM04HkDnk1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Validation_Input_3D_Patche.shape)\n",
        "print(Validation_Mask_3D_Patche.shape)\n",
        "print(Train_Input_3D_Patche.shape)\n",
        "print(Train_Mask_3D_Patche.shape)"
      ],
      "metadata": {
        "id": "JFzlwkZOnyC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Train U_NET Model using Training Samples\n",
        "\n",
        "results = model.fit(Train_Input_3D_Patche, Train_Mask_3D_Patche,\n",
        "                    validation_data=(Validation_Input_3D_Patche, Validation_Mask_3D_Patche),\n",
        "                    batch_size=2,\n",
        "                    epochs=100,\n",
        "                    callbacks=[checkpointer])\n",
        "#callbacks=[earlystopper, checkpointer, loss_history()]"
      ],
      "metadata": {
        "id": "2OTTTKwmEAD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Show Loss and ACC Plots\n",
        "\n",
        "\n",
        "# 11.1. Summarize History for Loss\n",
        "\n",
        "plt.plot(results.history['loss'])\n",
        "plt.plot(results.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 11.1. Summarize History for IOU\n",
        "\n",
        "plt.plot(results.history['io_u_3'])\n",
        "plt.plot(results.history['val_io_u_3'])\n",
        "plt.title('Yotal IOU')\n",
        "plt.ylabel('T-IOU')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 11.1. Summarize History for IOU\n",
        "\n",
        "plt.plot(results.history['io_u_4'])\n",
        "plt.plot(results.history['val_io_u_4'])\n",
        "plt.title('Pore IOU')\n",
        "plt.ylabel('P-IOU')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for IOU\n",
        "\n",
        "plt.plot(results.history['io_u_5'])\n",
        "plt.plot(results.history['val_io_u_5'])\n",
        "plt.title('Matrix IOU')\n",
        "plt.ylabel('M-IOU')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 11.1. Summarize History for Jacard Coef\n",
        "\n",
        "plt.plot(results.history['jacard_coef'])\n",
        "plt.plot(results.history['val_jacard_coef'])\n",
        "plt.title('Jaccard Coefficient')\n",
        "plt.ylabel('JC')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2buaQ3B-EFDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_Input = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Image_512x512/*.png\"))]\n",
        "Test_Mask = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Label_512x512/*.png\"))]\n",
        "\n",
        "Test_Input = np.array(Test_Input)\n",
        "Test_Mask = np.array(Test_Mask)\n",
        "\n",
        "Test_Mask = cv2.normalize(Test_Mask, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ],
      "metadata": {
        "id": "8IrHhrjiEIkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_Input_3D = np.stack(Test_Input, axis=2)\n",
        "Test_Mask_3D = np.stack(Test_Mask, axis=2)"
      ],
      "metadata": {
        "id": "vXIxg5GqEK0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_Input_3D_Patches = patchify(Test_Input_3D,(128,128,128), step=128)\n",
        "Test_Mask_3D_Patches = patchify(Test_Mask_3D,(128,128,128), step=128)"
      ],
      "metadata": {
        "id": "a5UP9i7OEMv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_Input_3D_Patche = np.reshape(Test_Input_3D_Patches, (-1, Test_Input_3D_Patches.shape[3], Test_Input_3D_Patches.shape[4], Test_Input_3D_Patches.shape[5]))\n",
        "Test_Mask_3D_Patche = np.reshape(Test_Mask_3D_Patches, (-1, Test_Input_3D_Patches.shape[3], Test_Input_3D_Patches.shape[4], Test_Input_3D_Patches.shape[5]))"
      ],
      "metadata": {
        "id": "L2lR5E5GEPCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_Mask_3D_Patche.shape"
      ],
      "metadata": {
        "id": "sW1MoqayERHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Results = model.evaluate(Test_Input_3D_Patche, Test_Mask_3D_Patche, batch_size=2)"
      ],
      "metadata": {
        "id": "12SRrrl3ETap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_Input_1 = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Buff_Berea_Sand/Image_512x512/*.png\"))]\n",
        "Test_Mask_1 = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Buff_Berea_Sand/Label_512x512/*.png\"))]\n",
        "\n",
        "Test_Input_1 = np.array(Test_Input_1)\n",
        "Test_Mask_1 = np.array(Test_Mask_1)\n",
        "\n",
        "Test_Mask_1 = cv2.normalize(Test_Mask_1, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ],
      "metadata": {
        "id": "ijas-pfRtkvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_Input_3D_1 = np.stack(Test_Input_1, axis=2)\n",
        "Test_Mask_3D_1 = np.stack(Test_Mask_1, axis=2)\n",
        "\n",
        "Test_Input_3D_Patches_1 = patchify(Test_Input_3D_1,(128,128,128), step=128)\n",
        "Test_Mask_3D_Patches_1 = patchify(Test_Mask_3D_1,(128,128,128), step=128)\n",
        "\n",
        "Test_Input_3D_Patche_1 = np.reshape(Test_Input_3D_Patches_1, (-1, Test_Input_3D_Patches_1.shape[3], Test_Input_3D_Patches_1.shape[4], Test_Input_3D_Patches_1.shape[5]))\n",
        "Test_Mask_3D_Patche_1 = np.reshape(Test_Mask_3D_Patches_1, (-1, Test_Input_3D_Patches_1.shape[3], Test_Input_3D_Patches_1.shape[4], Test_Input_3D_Patches_1.shape[5]))\n",
        "\n",
        "Test_Mask_3D_Patche_1.shape"
      ],
      "metadata": {
        "id": "JIsviHo9t11i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Results = model.evaluate(Test_Input_3D_Patche_1, Test_Mask_3D_Patche_1, batch_size=2)"
      ],
      "metadata": {
        "id": "QormF8BrvGZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_Input_2 = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Berea_Sand_Texas/Image_Berea_UF_512_/*.png\"))]\n",
        "Test_Mask_2 = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Berea_Sand_Texas/Mask_Berea_512_/*.png\"))]\n",
        "\n",
        "Test_Input_2 = np.array(Test_Input_2)\n",
        "Test_Mask_2 = np.array(Test_Mask_2)\n",
        "\n",
        "Test_Mask_2 = cv2.normalize(Test_Mask_2, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ],
      "metadata": {
        "id": "StYqmYRtvT2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_Input_3D_2 = np.stack(Test_Input_2, axis=2)\n",
        "Test_Mask_3D_2 = np.stack(Test_Mask_2, axis=2)\n",
        "\n",
        "Test_Input_3D_Patches_2 = patchify(Test_Input_3D_2,(128,128,128), step=128)\n",
        "Test_Mask_3D_Patches_2 = patchify(Test_Mask_3D_2,(128,128,128), step=128)\n",
        "\n",
        "Test_Input_3D_Patche_2 = np.reshape(Test_Input_3D_Patches_2, (-1, Test_Input_3D_Patches_2.shape[3], Test_Input_3D_Patches_2.shape[4], Test_Input_3D_Patches_2.shape[5]))\n",
        "Test_Mask_3D_Patche_2 = np.reshape(Test_Mask_3D_Patches_2, (-1, Test_Input_3D_Patches_2.shape[3], Test_Input_3D_Patches_2.shape[4], Test_Input_3D_Patches_2.shape[5]))\n",
        "\n",
        "Test_Mask_3D_Patche_2.shape"
      ],
      "metadata": {
        "id": "biTxOmjewBts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Results = model.evaluate(Test_Input_3D_Patche_2, Test_Mask_3D_Patche_2, batch_size=2)"
      ],
      "metadata": {
        "id": "J5FOutNLwYLI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}