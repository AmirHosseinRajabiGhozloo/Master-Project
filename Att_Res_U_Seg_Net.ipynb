{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqilwDpKSz73"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxR4gaDloZCG"
      },
      "outputs": [],
      "source": [
        "# 1. Import Required Modules\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import keras\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers import *\n",
        "import keras.backend as k\n",
        "from keras.models import *\n",
        "from keras.optimizers import *\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread, imshow, imsave, imread_collection\n",
        "from keras.losses import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzZUNvadS_GQ"
      },
      "outputs": [],
      "source": [
        "# 2. Define Train & Test Path (Images + Mask Path for Train and Test Stages)\n",
        "\n",
        "TRAIN_IMAGE_PATH = 'gdrive/My Drive/Sand_data/Sand_data/Sand_data/image'\n",
        "TRAIN_MASK_PATH = 'gdrive/My Drive/Sand_data/Sand_data/Sand_data/label'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tG7aYuyFolOA"
      },
      "outputs": [],
      "source": [
        "# 3. Initialize Images and Mask Size\n",
        "\n",
        "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 512, 512, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALBCkdJ-TDwY"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import cv2\n",
        "\n",
        "Train_Input = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Bandera_Gray_Sand/Image_512x512/*.png\"))]\n",
        "Train_Mask = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Bandera_Gray_Sand/Label_512x512/*.png\"))]\n",
        "\n",
        "Train_Input = np.array(Train_Input)\n",
        "Train_Mask = np.array(Train_Mask)\n",
        "\n",
        "Train_Mask = cv2.normalize(Train_Mask, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMZs-mDuTHiB"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import cv2\n",
        "\n",
        "Train_Input_1 = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Berea_Sand/Image_512x512/Image_512x512/*.png\"))]\n",
        "Train_Mask_1 = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Berea_Sand/Label_512x512/Label_512x512/*.png\"))]\n",
        "\n",
        "Train_Input_1 = np.array(Train_Input_1)\n",
        "Train_Mask_1 = np.array(Train_Mask_1)\n",
        "\n",
        "Train_Mask_1 = cv2.normalize(Train_Mask_1, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWGyomSFTEis"
      },
      "outputs": [],
      "source": [
        "Train_Input = (Train_Input, Train_Input_1)\n",
        "Train_Mask = (Train_Mask, Train_Mask_1)\n",
        "\n",
        "Train_Input = np.array(Train_Input)\n",
        "Train_Mask = np.array(Train_Mask)\n",
        "\n",
        "Train_Input = np.reshape(Train_Input, (-1, Train_Input.shape[2], Train_Input.shape[3]))\n",
        "Train_Mask = np.reshape(Train_Mask, (-1, Train_Mask.shape[2], Train_Mask.shape[3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kunNflFyTPY0"
      },
      "outputs": [],
      "source": [
        "print(Train_Mask.shape)\n",
        "\n",
        "print('Training Input')\n",
        "imshow(Train_Input[0])\n",
        "plt.show()\n",
        "\n",
        "print('Training Mask')\n",
        "imshow(np.squeeze(Train_Mask[0]), cmap='Greys_r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caPEkbR1o-go"
      },
      "outputs": [],
      "source": [
        "def dice_loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.math.sigmoid(y_pred)\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "\n",
        "    return 1 - numerator / denominator\n",
        "\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = k.flatten(y_true)\n",
        "    y_pred_f = k.flatten(y_pred)\n",
        "    intersection = k.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (k.sum(y_true_f) + k.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = k.sum(k.abs(y_true * y_pred), axis=[1,2])\n",
        "  union = k.sum(y_true,[1,2])+k.sum(y_pred,[1,2])-intersection\n",
        "  iou = k.mean((intersection+smooth) / (union+smooth), axis=0)\n",
        "  return iou\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = k.sum(k.round(k.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = k.sum(k.round(k.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + k.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = k.sum(k.round(k.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = k.sum(k.round(k.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + k.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "   precision = precision_m(y_true, y_pred)\n",
        "   recall = recall_m(y_true, y_pred)\n",
        "   return 2*((precision*recall)/(precision+recall+k.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svUMnYNMR6d7"
      },
      "outputs": [],
      "source": [
        "class MaxPoolingWithArgmax2D(Layer):\n",
        "    def __init__(self, pool_size=(2, 2), strides=(2, 2), padding=\"same\", **kwargs):\n",
        "        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n",
        "        self.padding = padding\n",
        "        self.pool_size = pool_size\n",
        "        self.strides = strides\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        padding = self.padding\n",
        "        pool_size = self.pool_size\n",
        "        strides = self.strides\n",
        "        if k.backend() == \"tensorflow\":\n",
        "            ksize = [1, pool_size[0], pool_size[1], 1]\n",
        "            padding = padding.upper()\n",
        "            strides = [1, strides[0], strides[1], 1]\n",
        "            output, argmax = k.tf.nn.max_pool_with_argmax(\n",
        "                inputs, ksize=ksize, strides=strides, padding=padding\n",
        "            )\n",
        "        else:\n",
        "            errmsg = \"{} backend is not supported for layer {}\".format(\n",
        "                k.backend(), type(self).__name__\n",
        "            )\n",
        "            raise NotImplementedError(errmsg)\n",
        "        argmax = k.cast(argmax, k.floatx())\n",
        "        return [output, argmax]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        ratio = (1, 2, 2, 1)\n",
        "        output_shape = [\n",
        "            dim // ratio[idx] if dim is not None else None\n",
        "            for idx, dim in enumerate(input_shape)\n",
        "        ]\n",
        "        output_shape = tuple(output_shape)\n",
        "        return [output_shape, output_shape]\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return 2 * [None]\n",
        "\n",
        "\n",
        "class MaxUnpooling2D(Layer):\n",
        "    def __init__(self, size=(2, 2), **kwargs):\n",
        "        super(MaxUnpooling2D, self).__init__(**kwargs)\n",
        "        self.size = size\n",
        "\n",
        "    def call(self, inputs, output_shape=None):\n",
        "        updates, mask = inputs[0], inputs[1]\n",
        "        with k.tf.compat.v1.variable_scope(self.name):\n",
        "            mask = k.cast(mask, \"int32\")\n",
        "            input_shape = k.tf.shape(updates, out_type=\"int32\")\n",
        "            #  calculation new shape\n",
        "            if output_shape is None:\n",
        "                output_shape = (\n",
        "                    input_shape[0],\n",
        "                    input_shape[1] * self.size[0],\n",
        "                    input_shape[2] * self.size[1],\n",
        "                    input_shape[3],\n",
        "                )\n",
        "            self.output_shape1 = output_shape\n",
        "\n",
        "            # calculation indices for batch, height, width and feature maps\n",
        "            one_like_mask = k.ones_like(mask, dtype=\"int32\")\n",
        "            batch_shape = k.concatenate([[input_shape[0]], [1], [1], [1]], axis=0)\n",
        "            batch_range = k.reshape(\n",
        "                k.tf.range(output_shape[0], dtype=\"int32\"), shape=batch_shape\n",
        "            )\n",
        "            b = one_like_mask * batch_range\n",
        "            y = mask // (output_shape[2] * output_shape[3])\n",
        "            x = (mask // output_shape[3]) % output_shape[2]\n",
        "            feature_range = k.tf.range(output_shape[3], dtype=\"int32\")\n",
        "            f = one_like_mask * feature_range\n",
        "\n",
        "            # transpose indices & reshape update values to one dimension\n",
        "            updates_size = k.tf.size(updates)\n",
        "            indices = k.transpose(k.reshape(k.stack([b, y, x, f]), [4, updates_size]))\n",
        "            values = k.reshape(updates, [updates_size])\n",
        "            ret = k.tf.scatter_nd(indices, values, output_shape)\n",
        "            return ret\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        mask_shape = input_shape[1]\n",
        "        return (\n",
        "            mask_shape[0],\n",
        "            mask_shape[1] * self.size[0],\n",
        "            mask_shape[2] * self.size[1],\n",
        "            mask_shape[3],\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJif_aJCSEwY"
      },
      "outputs": [],
      "source": [
        "def Att_Res_U_Seg_Net_2D_Segmentation(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "\n",
        "    inputs = Input(input_size)\n",
        "    print(inputs.shape)\n",
        "    n = Lambda(lambda x:x/255)(inputs)\n",
        "\n",
        "\n",
        "    c1 = Conv2D(16, (3,3), activation='relu', padding='same', kernel_initializer=tf.keras.initializers.Ones())(n)\n",
        "    c1 = Conv2D(16, (7,7), activation='relu', padding='same')(c1)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(16, (3,3), activation='relu', padding='same')(c1)\n",
        "\n",
        "    shortcut1 = Conv2D(16, (1,1), padding='same')(n)\n",
        "\n",
        "    Res_Path1 = add([shortcut1,c1])\n",
        "    out1 = Activation('relu')(Res_Path1)\n",
        "\n",
        "\n",
        "    #p1 = MaxPooling2D((2,2))(c1)\n",
        "    p1, mask_1 = MaxPoolingWithArgmax2D((2,2))(out1)\n",
        "\n",
        "\n",
        "    c2 = Conv2D(32, (3,3), activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(32, (7,7), activation='relu', padding='same')(c2)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(32, (3,3), activation='relu', padding='same')(c2)\n",
        "\n",
        "    shortcut2 = Conv2D(32, (1,1), padding='same')(p1)\n",
        "\n",
        "    Res_Path2 = add([shortcut2,c2])\n",
        "    out2 = Activation('relu')(Res_Path2)\n",
        "\n",
        "\n",
        "    #p2 = MaxPooling2D((2,2))(c2)\n",
        "    p2, mask_2 = MaxPoolingWithArgmax2D((2,2))(out2)\n",
        "\n",
        "\n",
        "    c3 = Conv2D(64, (3,3), activation='relu', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (7,7), activation='relu', padding='same')(c3)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3,3), activation='relu', padding='same')(c3)\n",
        "\n",
        "    shortcut3 = Conv2D(64, (1,1), padding='same')(p2)\n",
        "\n",
        "    Res_Path3 = add([shortcut3,c3])\n",
        "    out3 = Activation('relu')(Res_Path3)\n",
        "\n",
        "\n",
        "    #p3 = MaxPooling2D((2,2))(c3)\n",
        "    p3, mask_3 = MaxPoolingWithArgmax2D((2,2))(out3)\n",
        "\n",
        "\n",
        "    c4 = Conv2D(128, (3,3), activation='relu', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (7,7), activation='relu', padding='same')(c4)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3,3), activation='relu', padding='same')(c4)\n",
        "\n",
        "    shortcut4 = Conv2D(128, (1,1), padding='same')(p3)\n",
        "\n",
        "    Res_Path4 = add([shortcut4,c4])\n",
        "    out4 = Activation('relu')(Res_Path4)\n",
        "\n",
        "    #p4 = MaxPooling2D((2,2))(c4)\n",
        "    p4, mask_4 = MaxPoolingWithArgmax2D((2,2))(out4)\n",
        "\n",
        "\n",
        "    c5 = Conv2D(256, (3,3), activation='relu', padding='same')(p4)\n",
        "    c5 = Dropout(0.2)(c5)\n",
        "    c5 = Conv2D(256, (7,7), activation='relu', padding='same')(c5)\n",
        "    c5 = Dropout(0.2)(c5)\n",
        "    c5 = Conv2D(256, (3,3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    shortcut5 = Conv2D(256, (1,1), padding='same')(p4)\n",
        "\n",
        "    Res_Path5 = add([shortcut5,c5])\n",
        "    out5 = Activation('relu')(Res_Path5)\n",
        "\n",
        "\n",
        "    p5, mask_5 = MaxPoolingWithArgmax2D((2,2))(out5)\n",
        "\n",
        "\n",
        "    #u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
        "    #u6 = concatenate([u6, c4])\n",
        "    up1 = MaxUnpooling2D((2,2))([p5, mask_5])\n",
        "\n",
        "    theta_x_1 = Conv2D(64, (1,1), strides=(2,2), padding='same')(out5)\n",
        "    #theta_x_1 = BatchNormalization(axis=3)(theta_x_1)\n",
        "    shape_x_1 = k.int_shape(out5)\n",
        "    phi_g_1 = Conv2D(64, (1,1), strides=(1,1), padding='same')(p5)\n",
        "    #phi_g_1 = BatchNormalization(axis=3)(phi_g_1)\n",
        "    conc_xg_1 = add([phi_g_1, theta_x_1])\n",
        "    act_xg_1 = Activation('relu')(conc_xg_1)\n",
        "    psi_1 = Conv2D(1, (1,1), strides=(1,1), padding='same')(act_xg_1)\n",
        "    #psi_1 = BatchNormalization(axis=3)(psi_1)\n",
        "    sigm_xg_1 = Activation('sigmoid')(psi_1)\n",
        "    shape_sigm_1 = k.int_shape(sigm_xg_1)\n",
        "    upsample_xg_1 = UpSampling2D(size=(shape_x_1[1]//shape_sigm_1[1], shape_x_1[2]//shape_sigm_1[2]))(sigm_xg_1)\n",
        "    y1 = multiply([upsample_xg_1, out5])\n",
        "\n",
        "\n",
        "    u6 = concatenate([up1, y1])\n",
        "\n",
        "\n",
        "    c6 = Conv2D(256, (3,3), activation='relu', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(256, (7,7), activation='relu', padding='same')(c6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3,3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    shortcut6 = Conv2D(128, (1,1), padding='same')(u6)\n",
        "\n",
        "    Res_Path6 = add([shortcut6,c6])\n",
        "    out6 = Activation('relu')(Res_Path6)\n",
        "\n",
        "\n",
        "    #u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
        "    #u7 = concatenate([u7, c3])\n",
        "    up2 = MaxUnpooling2D((2,2))([out6, mask_4])\n",
        "\n",
        "\n",
        "    theta_x_2 = Conv2D(128, (1,1), strides=(2,2), padding='same')(out4)\n",
        "    #theta_x_2 = BatchNormalization(axis=3)(theta_x_2)\n",
        "    shape_x_2 = k.int_shape(out4)\n",
        "    phi_g_2 = Conv2D(128, (1,1), strides=(1,1), padding='same')(out6)\n",
        "    #phi_g_2 = BatchNormalization(axis=3)(phi_g_2)\n",
        "    conc_xg_2 = add([phi_g_2, theta_x_2])\n",
        "    act_xg_2 = Activation('relu')(conc_xg_2)\n",
        "    psi_2 = Conv2D(1, (1,1), strides=(1,1), padding='same')(act_xg_2)\n",
        "    #psi_2 = BatchNormalization(axis=3)(psi_2)\n",
        "    sigm_xg_2 = Activation('sigmoid')(psi_2)\n",
        "    shape_sigm_2 = k.int_shape(sigm_xg_2)\n",
        "    upsample_xg_2 = UpSampling2D(size=(shape_x_2[1]//shape_sigm_2[1], shape_x_2[2]//shape_sigm_2[2]))(sigm_xg_2)\n",
        "    y2 = multiply([upsample_xg_2, out4])\n",
        "\n",
        "\n",
        "    u7 = concatenate([up2, y2])\n",
        "\n",
        "\n",
        "    c7 = Conv2D(128, (3,3), activation='relu', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(128, (7,7), activation='relu', padding='same')(c7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3,3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    shortcut7 = Conv2D(64, (1,1), padding='same')(u7)\n",
        "\n",
        "    Res_Path7 = add([shortcut7,c7])\n",
        "    out7 = Activation('relu')(Res_Path7)\n",
        "\n",
        "\n",
        "    #u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
        "    #u8 = concatenate([u8, c2])\n",
        "    up3 = MaxUnpooling2D((2,2))([out7, mask_3])\n",
        "\n",
        "\n",
        "    theta_x_3 = Conv2D(256, (1,1), strides=(2,2), padding='same')(out3)\n",
        "    #theta_x_3 = BatchNormalization(axis=3)(theta_x_3)\n",
        "    shape_x_3 = k.int_shape(out3)\n",
        "    phi_g_3 = Conv2D(256, (1,1), strides=(1,1), padding='same')(out7)\n",
        "    #phi_g_3 = BatchNormalization(axis=3)(phi_g_3)\n",
        "    conc_xg_3 = add([phi_g_3, theta_x_3])\n",
        "    act_xg_3 = Activation('relu')(conc_xg_3)\n",
        "    psi_3 = Conv2D(1, (1,1), strides=(1,1), padding='same')(act_xg_3)\n",
        "    #psi_3 = BatchNormalization(axis=3)(psi_3)\n",
        "    sigm_xg_3 = Activation('sigmoid')(psi_3)\n",
        "    shape_sigm_3 = k.int_shape(sigm_xg_3)\n",
        "    upsample_xg_3 = UpSampling2D(size=(shape_x_3[1]//shape_sigm_3[1], shape_x_3[2]//shape_sigm_3[2]))(sigm_xg_3)\n",
        "    y3 = multiply([upsample_xg_3, out3])\n",
        "\n",
        "\n",
        "    u8 = concatenate([up3, y3])\n",
        "\n",
        "\n",
        "    c8 = Conv2D(64, (3,3), activation='relu', padding='same')(u8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(64, (7,7), activation='relu', padding='same')(c8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(32, (3,3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    shortcut8 = Conv2D(32, (1,1), padding='same')(u8)\n",
        "\n",
        "    Res_Path8 = add([shortcut8,c8])\n",
        "    out8 = Activation('relu')(Res_Path8)\n",
        "\n",
        "\n",
        "    #u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
        "    #u9 = concatenate([u9, c1], axis = 3)\n",
        "    up4 = MaxUnpooling2D((2,2))([out8, mask_2])\n",
        "\n",
        "\n",
        "    theta_x_4 = Conv2D(512, (1,1), strides=(2,2), padding='same')(out2)\n",
        "    #theta_x_4 = BatchNormalization(axis=3)(theta_x_4)\n",
        "    shape_x_4 = k.int_shape(out2)\n",
        "    phi_g_4 = Conv2D(512, (1,1), strides=(1,1), padding='same')(out8)\n",
        "    #phi_g_4 = BatchNormalization(axis=3)(phi_g_4)\n",
        "    conc_xg_4 = add([phi_g_4, theta_x_4])\n",
        "    act_xg_4 = Activation('relu')(conc_xg_4)\n",
        "    psi_4 = Conv2D(1, (1,1), strides=(1,1), padding='same')(act_xg_4)\n",
        "    #psi_4 = BatchNormalization(axis=3)(psi_4)\n",
        "    sigm_xg_4 = Activation('sigmoid')(psi_4)\n",
        "    shape_sigm_4 = k.int_shape(sigm_xg_4)\n",
        "    upsample_xg_4 = UpSampling2D(size=(shape_x_4[1]//shape_sigm_4[1], shape_x_4[2]//shape_sigm_4[2]))(sigm_xg_4)\n",
        "    y4 = multiply([upsample_xg_4, out2])\n",
        "\n",
        "\n",
        "    u9 = concatenate([up4, y4])\n",
        "\n",
        "\n",
        "    c9 = Conv2D(32, (3,3), activation='relu', padding='same')(u9)\n",
        "    c9 = Conv2D(16, (7,7), activation='relu', padding='same')(c9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(16, (3,3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    shortcut9 = Conv2D(16, (1,1), padding='same')(u9)\n",
        "\n",
        "    Res_Path9 = add([shortcut9,c9])\n",
        "    out9 = Activation('relu')(Res_Path9)\n",
        "\n",
        "\n",
        "    up5 = MaxUnpooling2D((2,2))([out9, mask_1])\n",
        "\n",
        "\n",
        "    theta_x_5 = Conv2D(1024, (1,1), strides=(2,2), padding='same')(out1)\n",
        "    #theta_x_5 = BatchNormalization(axis=3)(theta_x_5)\n",
        "    shape_x_5 = k.int_shape(out1)\n",
        "    phi_g_5 = Conv2D(1024, (1,1), strides=(1,1), padding='same')(out9)\n",
        "    #phi_g_5 = BatchNormalization(axis=3)(phi_g_5)\n",
        "    conc_xg_5 = add([phi_g_5, theta_x_5])\n",
        "    act_xg_5 = Activation('relu')(conc_xg_5)\n",
        "    psi_5 = Conv2D(1, (1,1), strides=(1,1), padding='same')(act_xg_5)\n",
        "    #psi_5 = BatchNormalization(axis=3)(psi_5)\n",
        "    sigm_xg_5 = Activation('sigmoid')(psi_5)\n",
        "    shape_sigm_5 = k.int_shape(sigm_xg_5)\n",
        "    upsample_xg_5 = UpSampling2D(size=(shape_x_5[1]//shape_sigm_5[1], shape_x_5[2]//shape_sigm_5[2]))(sigm_xg_5)\n",
        "    y5 = multiply([upsample_xg_5, out1])\n",
        "\n",
        "\n",
        "    u10 = concatenate([up5, y5])\n",
        "\n",
        "\n",
        "    c10 = Conv2D(16, (3,3), activation='relu', padding='same')(u10)\n",
        "    c10 = Conv2D(16, (7,7), activation='relu', padding='same')(c10)\n",
        "    c10 = Dropout(0.1)(c10)\n",
        "    c10 = Conv2D(16, (3,3), activation='relu', padding='same')(c10)\n",
        "\n",
        "    shortcut10 = Conv2D(16, (1,1), padding='same')(u10)\n",
        "\n",
        "    Res_Path10 = add([shortcut10,c10])\n",
        "    out10 = Activation('relu')(Res_Path10)\n",
        "\n",
        "    print(inputs.shape)\n",
        "\n",
        "\n",
        "\n",
        "    outputs = Conv2D(1,(1,1), activation='sigmoid')(out10)\n",
        "    print(outputs.shape)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss = ['binary_crossentropy'], metrics=[tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0, 1]), tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0]), tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1]), f1_m ,precision_m , recall_m, 'accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcmWRv57opih"
      },
      "outputs": [],
      "source": [
        "model = Att_Res_U_Seg_Net_2D_Segmentation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSNzW6koTgPC"
      },
      "outputs": [],
      "source": [
        "# 7. Show The Results per Epoch\n",
        "\n",
        "class loss_history(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__ (self, x=4):\n",
        "        self.x = x\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "\n",
        "        imshow(np.squeeze(Train_Input[self.x]))\n",
        "        plt.show()\n",
        "\n",
        "        imshow(np.squeeze(Train_Mask[self.x]), cmap='Greys_r')\n",
        "        plt.show()\n",
        "\n",
        "        preds_train = self.model.predict(np.expand_dims(Train_Input[self.x], axis = 0))\n",
        "        imshow(np.squeeze(preds_train[0]), cmap='Greys_r')\n",
        "        plt.show()\n",
        "\n",
        "Model_Path = 'gdrive/My Drive/Saved_Models/2D_Att_Res_U_Seg_Net/Bandera_Berea_IoU_Modified_2D_Att_Res_U_Net_BCE_0005_Ones_BTN'\n",
        "\n",
        "earlystopper = EarlyStopping(patience=15, verbose=1)\n",
        "checkpointer = ModelCheckpoint(Model_Path, verbose = 1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAvrCmn-T4AE"
      },
      "outputs": [],
      "source": [
        "Validation_Input = Train_Input[1600:]\n",
        "Train_Input = Train_Input[:1600]\n",
        "Validation_Mask = Train_Mask[1600:]\n",
        "Train_Mask = Train_Mask[:1600]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07m4Pzsna5I_"
      },
      "outputs": [],
      "source": [
        "Train_Input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TythEptcT7kn"
      },
      "outputs": [],
      "source": [
        "Train_Mask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WThJ5IVoT9Cv"
      },
      "outputs": [],
      "source": [
        "# 8. Train U_NET Model using Training Samples\n",
        "\n",
        "results = model.fit(Train_Input, Train_Mask,\n",
        "                    validation_data=(Validation_Input, Validation_Mask),\n",
        "                    batch_size=4,\n",
        "                    epochs=40\n",
        "                    , callbacks=[checkpointer, loss_history()])\n",
        "#earlystopper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MmjzQ_IjcTM"
      },
      "outputs": [],
      "source": [
        "preds_train = model.predict(Train_Input, batch_size=4)\n",
        "preds_train_t = preds_train.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL-ahQXhKZAc"
      },
      "outputs": [],
      "source": [
        "# 11. Show Loss and ACC Plots\n",
        "\n",
        "\n",
        "# 11.1. Summarize History for Loss\n",
        "\n",
        "plt.plot(results.history['loss'])\n",
        "plt.plot(results.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 11.1. Summarize History for IOU\n",
        "\n",
        "plt.plot(results.history['io_u'])\n",
        "plt.plot(results.history['val_io_u'])\n",
        "plt.title('iou_coef')\n",
        "plt.ylabel('IOU')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for IOU\n",
        "\n",
        "plt.plot(results.history['io_u_1'])\n",
        "plt.plot(results.history['val_io_u_1'])\n",
        "plt.title('iou_coef')\n",
        "plt.ylabel('IOU')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for IOU\n",
        "\n",
        "plt.plot(results.history['io_u_2'])\n",
        "plt.plot(results.history['val_io_u_2'])\n",
        "plt.title('iou_coef')\n",
        "plt.ylabel('IOU')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for Precision\n",
        "\n",
        "plt.plot(results.history['precision_m'])\n",
        "plt.plot(results.history['val_precision_m'])\n",
        "plt.title('Precision')\n",
        "plt.ylabel('Prec')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for Recall\n",
        "\n",
        "plt.plot(results.history['recall_m'])\n",
        "plt.plot(results.history['val_recall_m'])\n",
        "plt.title('Recal')\n",
        "plt.ylabel('Recl')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for F1_Score\n",
        "\n",
        "plt.plot(results.history['f1_m'])\n",
        "plt.plot(results.history['val_f1_m'])\n",
        "plt.title('F1 Score')\n",
        "plt.ylabel('F1')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for Jacard Coef\n",
        "\n",
        "#plt.plot(results.history['jacard_coef'])\n",
        "#plt.plot(results.history['val_jacard_coef'])\n",
        "#plt.title('Jaccard Coefficient')\n",
        "#plt.ylabel('JC')\n",
        "#plt.xlabel('epochs')\n",
        "#plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0rjkTtH5QlS"
      },
      "outputs": [],
      "source": [
        "Test_Input = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Buff_Berea_Sand/Image_512x512/*.png\"))]\n",
        "Test_Mask = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Buff_Berea_Sand/Label_512x512/*.png\"))]\n",
        "\n",
        "Test_Input = np.array(Test_Input)\n",
        "Test_Mask = np.array(Test_Mask)\n",
        "\n",
        "Test_Mask = cv2.normalize(Test_Mask, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC9hXzNP6mcq"
      },
      "outputs": [],
      "source": [
        "Results_BB = model.evaluate(Test_Input, Test_Mask, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Olhtb6UfKw6F"
      },
      "outputs": [],
      "source": [
        "preds_test = model.predict(Test_Input[214:218], batch_size=4)\n",
        "preds_test_t = preds_test.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzcbMbUw7lB6"
      },
      "outputs": [],
      "source": [
        "Diff_Image_1 = cv2.subtract(preds_test_t[1], Test_Mask[215])\n",
        "Diff_Image_1 = abs(Diff_Image_1)\n",
        "\n",
        "Diff_Image = cv2.subtract(Test_Mask[215], preds_test_t[1])\n",
        "Diff_Image = abs(Diff_Image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZOyEY_I8AnT"
      },
      "outputs": [],
      "source": [
        "Diff_Image_Final = add([Diff_Image, Diff_Image_1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K-j3rsv7tX1"
      },
      "outputs": [],
      "source": [
        "print('Predicted')\n",
        "imshow(np.squeeze(preds_test_t[1]), cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "print('Mask')\n",
        "imshow(np.squeeze(Test_Mask[215]), cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "print('Difference Image')\n",
        "imshow(np.squeeze(Diff_Image_Final), cmap='Greys')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcSOOXshA_O1"
      },
      "outputs": [],
      "source": [
        "Test_Input = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Berea_Sand/Image_512x512/Image_512x512/*.png\"))]\n",
        "Test_Mask = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Berea_Sand/Label_512x512/Label_512x512/*.png\"))]\n",
        "\n",
        "Test_Input = np.array(Test_Input)\n",
        "Test_Mask = np.array(Test_Mask)\n",
        "\n",
        "Test_Mask = cv2.normalize(Test_Mask, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeSVenqVBKd2"
      },
      "outputs": [],
      "source": [
        "Results_B = model.evaluate(Test_Input, Test_Mask, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRNiRtByBTyO"
      },
      "outputs": [],
      "source": [
        "preds_test = model.predict(Test_Input[214:218], batch_size=4)\n",
        "preds_test_t = preds_test.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUutKwgfBcV7"
      },
      "outputs": [],
      "source": [
        "Diff_Image_1 = cv2.subtract(preds_test_t[1], Test_Mask[215])\n",
        "Diff_Image_1 = abs(Diff_Image_1)\n",
        "\n",
        "Diff_Image = cv2.subtract(Test_Mask[215], preds_test_t[1])\n",
        "Diff_Image = abs(Diff_Image)\n",
        "\n",
        "Diff_Image_Final = add([Diff_Image, Diff_Image_1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlQWFp8DBrTF"
      },
      "outputs": [],
      "source": [
        "print('Predicted')\n",
        "imshow(np.squeeze(preds_test_t[0]), cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "print('Mask')\n",
        "imshow(np.squeeze(Test_Mask[215]), cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "print('Difference Image')\n",
        "imshow(np.squeeze(Diff_Image_Final), cmap='Greys')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W47Gq2T3CHM1"
      },
      "outputs": [],
      "source": [
        "Test_Input = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Parker_Sand/Image_512x512/*.png\"))]\n",
        "Test_Mask = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Parker_Sand/Label_512x512/*.png\"))]\n",
        "\n",
        "Test_Input = np.array(Test_Input)\n",
        "Test_Mask = np.array(Test_Mask)\n",
        "\n",
        "Test_Mask = cv2.normalize(Test_Mask, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LFk-E1va5Eu"
      },
      "outputs": [],
      "source": [
        "Results_L = model.evaluate(Test_Input, Test_Mask, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMtjcMTvCZBL"
      },
      "outputs": [],
      "source": [
        "preds_test = model.predict(Test_Input[214:218], batch_size=4)\n",
        "preds_test_t = preds_test.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPNuW3uJbJeY"
      },
      "outputs": [],
      "source": [
        "Diff_Image_1 = cv2.subtract(preds_test_t[1], Test_Mask[215])\n",
        "Diff_Image_1 = abs(Diff_Image_1)\n",
        "\n",
        "Diff_Image = cv2.subtract(Test_Mask[215], preds_test_t[1])\n",
        "Diff_Image = abs(Diff_Image)\n",
        "\n",
        "Diff_Image_Final = add([Diff_Image, Diff_Image_1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flSLdY2MbQE3"
      },
      "outputs": [],
      "source": [
        "print('Predicted')\n",
        "imshow(np.squeeze(preds_test_t[0]), cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "print('Mask')\n",
        "imshow(np.squeeze(Test_Mask[215]), cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "print('Difference Image')\n",
        "imshow(np.squeeze(Diff_Image_Final), cmap='Greys')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkdK9fMxb5FX"
      },
      "outputs": [],
      "source": [
        "Test_Input = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Leopard_Sand/Image_512x512/*.png\"))]\n",
        "Test_Mask = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Leopard_Sand/Label_512x512/*.png\"))]\n",
        "\n",
        "Test_Input = np.array(Test_Input)\n",
        "Test_Mask = np.array(Test_Mask)\n",
        "\n",
        "Test_Mask = cv2.normalize(Test_Mask, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK8u8Bttb-0X"
      },
      "outputs": [],
      "source": [
        "Results_L = model.evaluate(Test_Input, Test_Mask, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmC3zGo7cCdc"
      },
      "outputs": [],
      "source": [
        "preds_test = model.predict(Test_Input[214:218], batch_size=4)\n",
        "preds_test_t = preds_test.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0g9E-MxcG-Q"
      },
      "outputs": [],
      "source": [
        "Diff_Image_1 = cv2.subtract(preds_test_t[1], Test_Mask[215])\n",
        "Diff_Image_1 = abs(Diff_Image_1)\n",
        "\n",
        "Diff_Image = cv2.subtract(Test_Mask[215], preds_test_t[1])\n",
        "Diff_Image = abs(Diff_Image)\n",
        "\n",
        "Diff_Image_Final = add([Diff_Image, Diff_Image_1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP9iqRgDcJSO"
      },
      "outputs": [],
      "source": [
        "print('Predicted')\n",
        "imshow(np.squeeze(preds_test_t[0]), cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "print('Mask')\n",
        "imshow(np.squeeze(Test_Mask[215]), cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "print('Difference Image')\n",
        "imshow(np.squeeze(Diff_Image_Final), cmap='Greys')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}